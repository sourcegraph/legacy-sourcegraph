package search

import (
	"context"
	"strings"
	"testing"
	"time"

	"github.com/keegancsmith/sqlf"
	"github.com/stretchr/testify/require"

	"github.com/sourcegraph/sourcegraph/internal/actor"
	"github.com/sourcegraph/sourcegraph/internal/database"
	"github.com/sourcegraph/sourcegraph/internal/database/basestore"
	"github.com/sourcegraph/sourcegraph/internal/database/dbtest"
	"github.com/sourcegraph/sourcegraph/internal/observation"
	"github.com/sourcegraph/sourcegraph/internal/search/exhaustive/service"
	"github.com/sourcegraph/sourcegraph/internal/search/exhaustive/store"
	"github.com/sourcegraph/sourcegraph/internal/search/exhaustive/types"
)

func TestExhaustiveSearch(t *testing.T) {
	// TODO(keegan) I can imagine evolving this into a full e2e test using the
	// DB and the searcher fake to test all the worker tables.
	// TODO use searchJob to do initialization

	require := require.New(t)
	observationCtx := observation.TestContextTB(t)
	logger := observationCtx.Logger
	db := database.NewDB(logger, dbtest.NewDB(logger, t))
	s := store.New(db, observation.TestContextTB(t))

	ctx := actor.WithActor(context.Background(), &actor.Actor{Internal: true})
	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	userID := insertRow(t, s.Store, "users", "username", "alice")
	insertRow(t, s.Store, "repo", "id", 1, "name", "repoa")
	insertRow(t, s.Store, "repo", "id", 2, "name", "repob")

	query := "1@rev1 1@rev2 2@rev3"

	// Create a job
	jobID, err := s.CreateExhaustiveSearchJob(ctx, types.ExhaustiveSearchJob{
		InitiatorID: userID,
		Query:       query,
	})
	require.NoError(err)

	workerStore := store.NewExhaustiveSearchJobWorkerStore(observationCtx, db.Handle())
	worker := NewExhaustiveSearchWorker(
		ctx,
		observationCtx,
		workerStore,
		s,
		service.NewSearcherFake(),
	)

	go worker.Start()
	defer worker.Stop()

	// Wait until all work is done. QueuedCount(ctx, true) returns all work in
	// queue or currently being processed.
	require.Eventually(func() bool {
		count, _ := workerStore.QueuedCount(ctx, true)
		return count == 0
	}, tTimeout(t, 10*time.Second), 10*time.Millisecond)

	// We now validate by directly checking the entries are created that we
	// want.
	want := "1@spec 2@spec"
	rows, err := s.Store.Query(ctx, sqlf.Sprintf("SELECT CONCAT(repo_id, '@', ref_spec) AS part FROM exhaustive_search_repo_jobs WHERE search_job_id = %d ORDER BY part ASC", jobID))
	require.NoError(err)

	var gotParts []string
	for rows.Next() {
		var part string
		require.NoError(rows.Scan(&part))
		gotParts = append(gotParts, part)
	}
	require.NoError(rows.Err())

	got := strings.Join(gotParts, " ")
	require.Equal(want, got)
}

// insertRow is a helper for inserting a row into a table. It assumes the
// table has an autogenerated column called id and it will return that value.
func insertRow(t testing.TB, store *basestore.Store, table string, keyValues ...any) int32 {
	var columns, values []*sqlf.Query
	for i, kv := range keyValues {
		if i%2 == 0 {
			columns = append(columns, sqlf.Sprintf(kv.(string)))
		} else {
			values = append(values, sqlf.Sprintf("%v", kv))
		}
	}
	q := sqlf.Sprintf(`INSERT INTO %s(%s) VALUES(%s) RETURNING id`, sqlf.Sprintf(table), sqlf.Join(columns, ", "), sqlf.Join(values, ", "))
	row := store.QueryRow(context.Background(), q)
	var id int32
	if err := row.Scan(&id); err != nil {
		t.Fatal(err)
	}
	return id
}

// tTimeout returns the duration until t's deadline. If there is no deadline
// or the deadline is further away than max, then max is returned.
func tTimeout(t *testing.T, max time.Duration) time.Duration {
	deadline, ok := t.Deadline()
	if !ok {
		return max
	}
	timeout := time.Until(deadline)
	if max < timeout {
		return max
	}
	return timeout
}
